{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jokian-jedoy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNnPr8FhoUGMdBq2YvoQNkr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanggusti/30-days-kaggle/blob/main/jokian_jedoy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AukD6RrqtUXn"
      },
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install medmnist\n",
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f7fQACBpVbH"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm\n",
        "from skimage.util import montage\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "\n",
        "import medmnist\n",
        "from medmnist.dataset import PathMNIST, ChestMNIST, DermaMNIST, OCTMNIST, PneumoniaMNIST, RetinaMNIST, BreastMNIST, OrganMNISTAxial, OrganMNISTCoronal, OrganMNISTSagittal\n",
        "from medmnist.evaluator import getAUC, getACC\n",
        "from medmnist.info import INFO\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9LA_tLLwGlu"
      },
      "source": [
        "print(\"Version:\", medmnist.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk-se7POwK5O"
      },
      "source": [
        "flag_to_class = {\n",
        "    \"pathmnist\": PathMNIST,\n",
        "    \"chestmnist\": ChestMNIST,\n",
        "    \"dermamnist\": DermaMNIST,\n",
        "    \"octmnist\": OCTMNIST,\n",
        "    \"pneumoniamnist\": PneumoniaMNIST,\n",
        "    \"retinamnist\": RetinaMNIST,\n",
        "    \"breastmnist\": BreastMNIST,\n",
        "    \"organmnist_axial\": OrganMNISTAxial,\n",
        "    \"organmnist_coronal\": OrganMNISTCoronal,\n",
        "    \"organmnist_sagittal\": OrganMNISTSagittal,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mda7auxT63S4"
      },
      "source": [
        "## B. Logistic Regression on BreastMNIST\n",
        "\n",
        "Objectives:\n",
        "\n",
        "Built 2 models with these criteria:\n",
        "  - Using the built-in logistic regression functions in scikit-learn, train a logistic regression model with L2 regularisation on the training set, use the validation set to choose a good regularisation parameter (a hyperparameter) from at least three choices, and test the chosen model on the test set. Report the three metrics M1 to M3\n",
        "  - Using PyTorch (see Question 5 of Lab 6), train a logistic regression model with L2 regularisation on the training set, use the validation set to choose a good regularisation parameter (a hyperparameter) from at least three choices, and test the chosen model on the test set. Report the three metrics M1 to M3\n",
        "\n",
        "Get these metrics too\n",
        "\n",
        "1. Data loading and Inspection\n",
        "2. Logistic Regression using this [model](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
        "3. Track metrics:\n",
        "  - M1 Training accuracy\n",
        "  - M2 Validation accuracy\n",
        "  - M3 Testing accuracy\n",
        "4. Performance comparison:\n",
        "  - summarise each of the three metrics from the two mdoels using one or more bar graphs\n",
        "  - Describe at least two observations interesting to you\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9khwe_ET0G77"
      },
      "source": [
        "## Tuning Here\n",
        "\n",
        "Current: *BreastMNIST*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56mLsydyztaG"
      },
      "source": [
        "data_flag = 'breastmnist'\n",
        "download = True\n",
        "input_root = 'breastmnist/'\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "lr = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQYix4xCkJp5"
      },
      "source": [
        "!mkdir breastmnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU7_saMkz4Hg"
      },
      "source": [
        "DataClass = flag_to_class[data_flag]\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc7FChJywOu3"
      },
      "source": [
        "# preprocessing\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(root=input_root, split='train', transform=data_transform, download=download)\n",
        "validation_dataset = DataClass(root=input_root, split='val', transform=data_transform, download=download)\n",
        "test_dataset = DataClass(root=input_root, split='test', transform=data_transform, download=download)\n",
        "nonorm_dataset = DataClass(root=input_root, split='train', transform=transforms.ToTensor(), download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_loader = data.DataLoader(dataset=validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew3PqLyawqzh"
      },
      "source": [
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(validation_dataset)\n",
        "print(\"===================\")\n",
        "print(test_dataset)\n",
        "print(\"===================\")\n",
        "print(nonorm_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-vuLC8vwuyC"
      },
      "source": [
        "# visualization\n",
        "\n",
        "img, target = nonorm_dataset[0]\n",
        "if n_channels == 1:\n",
        "    img = img.reshape(28, 28)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "else:\n",
        "    img = img.permute(1, 2, 0)\n",
        "    plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVvBbbz1wyw0"
      },
      "source": [
        "# montage\n",
        "\n",
        "def process(n_channels, length=20):\n",
        "    scale = length * length\n",
        "\n",
        "    image = np.zeros((scale, 28, 28, 3)) if n_channels == 3 else np.zeros((scale, 28, 28))\n",
        "    index = [i for i in range(scale)]\n",
        "    np.random.shuffle(index)\n",
        "    \n",
        "    for idx in range(scale):\n",
        "        img, _ = nonorm_dataset[idx]\n",
        "        if n_channels == 3:\n",
        "            img = img.permute(1, 2, 0).numpy()\n",
        "        else:\n",
        "            img = img.reshape(28, 28).numpy()\n",
        "        image[index[idx]] = img\n",
        "\n",
        "    if n_channels == 1:\n",
        "        image = image.reshape(scale, 28, 28)\n",
        "        arr_out = montage(image)\n",
        "        plt.imshow(arr_out, cmap='gray')\n",
        "    else:\n",
        "        image = image.reshape(scale, 28, 28, 3)\n",
        "        arr_out = montage(image, multichannel=3)\n",
        "        plt.imshow(arr_out)\n",
        "    \n",
        "process(n_channels=n_channels, length=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc1FKaS8k8Dq"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "np.random.seed(2020) #set a seed for reproducibility\n",
        "clf = LogisticRegression(solver='lbfgs')  #clf: classifier\n",
        "clf.fit(sgx, sgy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7bVfcR__4j3"
      },
      "source": [
        "# here lies the logistic regression model for BreastMNIST\n",
        "# Logistic Regression using PyTorch\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x_in):\n",
        "        z = self.fc1(x_in)\n",
        "        return z\n",
        "\n",
        "model = LogisticRegression(input_dim=INPUT_DIM, num_classes=NUM_CLASSES)\n",
        "print (model.named_parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KEsJfA0kyBx"
      },
      "source": [
        "# write a function to get random samples (a batch) from sgx and sgy\n",
        "def get_batch_logi_regress(sgx,sgy,batch_size=32):\n",
        "\n",
        "    #create a vector with the indexes: from 0 to the size of the input data\n",
        "    indexes= torch.linspace(0,sgx.shape[0]-1,steps=sgx.shape[0])\n",
        "    \n",
        "    #sample random indicies from the vector above, these 32 \n",
        "    #random numbers are the row indexes for the batch data.\n",
        "    \n",
        "    random_indexes=torch.multinomial(indexes,32)\n",
        "    \n",
        "    batch_x= sgx[random_indexes]\n",
        "    batch_y= sgy[random_indexes]\n",
        "    \n",
        "    return batch_x, batch_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeLtuIuPj_G5"
      },
      "source": [
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "from itertools import count\n",
        "for batch_idx in count(1):\n",
        "    # Get data\n",
        "    batch_x, batch_y = get_batch_logi_regress(sgx,sgy)\n",
        "    # Reset gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    # however we need to change the above ndarray to torch\n",
        "    # tensors before calling the function LR.forward\n",
        "    \n",
        "    #warping ndarray to torch tensors\n",
        "    batch_x=(torch.from_numpy(batch_x.astype(np.float32)))\n",
        "    batch_y=(torch.from_numpy(batch_y.astype(np.float32)))\n",
        "    \n",
        "    \n",
        "    output = criterion(torch.squeeze(LR(batch_x)), batch_y)\n",
        "    loss = output.item()\n",
        "    \n",
        "    # Backward pass\n",
        "    output.backward()\n",
        "\n",
        "    # Apply gradients\n",
        "    for param in model.parameters():\n",
        "        param.data.add_(-0.5 * param.grad.data)\n",
        "\n",
        "    # Stop criterion\n",
        "    if abs(loss) < 1e-2:\n",
        "        break\n",
        "\n",
        "print('Loss: {:.6f} after {} batches'.format(loss, batch_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNxhI7Ut-Amh"
      },
      "source": [
        "## C. Convolutional Neural Network on OctMNIST\n",
        "1. Data loading and Inspection\n",
        "2. CNN with metrics:\n",
        "  - Training accuracy\n",
        "  - Validation accuracy\n",
        "  - Testing accuracy\n",
        "  - Training time\n",
        "\n",
        "Design two design of CNN with specified architecture\n",
        "- Design a CNN with two Conv layers and two FC layers. Train the model on the training set, use the validation set to choose the best design among at least three different choices, and test the chosen model on the test set. Report the four metrics M1 to M4\n",
        "- Design a CNN with three Conv layers and three FC layers. Train the model on the training set, use the validation set to choose the best design among at least three different choices, and test the chosen model on the test set. Report the four metrics M1 to M4\n",
        "\n",
        "3. Performance comparison\n",
        "  - Summarise each of the four metrics from the two models in 2 using one or more bar graphs\n",
        "  - Describe at least two observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2BaMR86AZxz"
      },
      "source": [
        "# Preprocessing, Data Loading and Inspection\n",
        "data_flag = 'octmnist'\n",
        "download = True\n",
        "input_root = 'octmnist/'\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "lr = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-JleQFPofUz"
      },
      "source": [
        "!mkdir octmnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfyXVz9kAj_m"
      },
      "source": [
        "DataClass = flag_to_class[data_flag]\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmJBdgFiAp8r"
      },
      "source": [
        "# preprocessing\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(root=input_root, split='train', transform=data_transform, download=download)\n",
        "validation_dataset = DataClass(root=input_root, split='val', transform=data_transform, download=download)\n",
        "test_dataset = DataClass(root=input_root, split='test', transform=data_transform, download=download)\n",
        "nonorm_dataset = DataClass(root=input_root, split='train', transform=transforms.ToTensor(), download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_loader = data.DataLoader(dataset=validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFnHt_eDAzAz"
      },
      "source": [
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(validation_dataset)\n",
        "print(\"===================\")\n",
        "print(test_dataset)\n",
        "print(\"===================\")\n",
        "print(nonorm_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT1PUfa5A17t"
      },
      "source": [
        "# visualization\n",
        "\n",
        "img, target = nonorm_dataset[0]\n",
        "if n_channels == 1:\n",
        "    img = img.reshape(28, 28)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "else:\n",
        "    img = img.permute(1, 2, 0)\n",
        "    plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUmmk9k2A4mr"
      },
      "source": [
        "# montage\n",
        "\n",
        "def process(n_channels, length=20):\n",
        "    scale = length * length\n",
        "\n",
        "    image = np.zeros((scale, 28, 28, 3)) if n_channels == 3 else np.zeros((scale, 28, 28))\n",
        "    index = [i for i in range(scale)]\n",
        "    np.random.shuffle(index)\n",
        "    \n",
        "    for idx in range(scale):\n",
        "        img, _ = nonorm_dataset[idx]\n",
        "        if n_channels == 3:\n",
        "            img = img.permute(1, 2, 0).numpy()\n",
        "        else:\n",
        "            img = img.reshape(28, 28).numpy()\n",
        "        image[index[idx]] = img\n",
        "\n",
        "    if n_channels == 1:\n",
        "        image = image.reshape(scale, 28, 28)\n",
        "        arr_out = montage(image)\n",
        "        plt.imshow(arr_out, cmap='gray')\n",
        "    else:\n",
        "        image = image.reshape(scale, 28, 28, 3)\n",
        "        arr_out = montage(image, multichannel=3)\n",
        "        plt.imshow(arr_out)\n",
        "    \n",
        "process(n_channels=n_channels, length=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfklxV8WZhTp"
      },
      "source": [
        "Design a CNN with **two Conv layers** and **two FC layers**. Train the model on the training set, use the validation set to choose the best design among at least three different choices, and test the chosen model on the test set. Report the four metrics M1 to M4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T00KKv4Pw6ta"
      },
      "source": [
        "# define a simple CNN model\n",
        "\n",
        "class CNN_A(nn.Module):\n",
        "    \"\"\"\n",
        "    2 Convolutional layers and 2 FC layers\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(CNN_A, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, kernel_size=3),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # self.layer3 = nn.Sequential(\n",
        "        #     nn.Conv2d(16, 64, kernel_size=3),\n",
        "        #     nn.BatchNorm2d(64),\n",
        "        #     nn.ReLU())\n",
        "        \n",
        "        # self.layer4 = nn.Sequential(\n",
        "        #     nn.Conv2d(64, 64, kernel_size=3),\n",
        "        #     nn.BatchNorm2d(64),\n",
        "        #     nn.ReLU())\n",
        "\n",
        "        # self.layer5 = nn.Sequential(\n",
        "        #     nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "        #     nn.BatchNorm2d(64),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64 * 4 * 4, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = CNN_A(in_channels=n_channels, num_classes=n_classes)\n",
        "print(model)\n",
        "    \n",
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsymwNEyTX1v"
      },
      "source": [
        "# wandb_logger = WandbLogger()\n",
        "# trainer = pl.Trainer(\n",
        "#     gpus = min(1, torch.cuda.device_count()),\n",
        "#     max_epochs=NUM_EPOCHS,\n",
        "#     progress_bar_refresh_rate=20,\n",
        "#     logger=wandb_logger\n",
        "# )\n",
        "\n",
        "# trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=validation_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjyPpQjjxT-m"
      },
      "source": [
        "wandblogger = WandbLogger()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    \n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        # forward + backward + optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = criterion(outputs, targets)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylrZlIMnxzg3"
      },
      "source": [
        "# evaluation\n",
        "\n",
        "def test(split):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([])\n",
        "    y_score = torch.tensor([])\n",
        "    \n",
        "    data_loader = train_loader if split == 'train' else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                m = nn.Sigmoid()\n",
        "                outputs = m(outputs)\n",
        "            else:\n",
        "                targets = targets.squeeze().long()\n",
        "                m = nn.Softmax(dim=1)\n",
        "                outputs = m(outputs)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "        y_true = y_true.numpy()\n",
        "        y_score = y_score.detach().numpy()\n",
        "        auc = getAUC(y_true, y_score, task)\n",
        "        acc = getACC(y_true, y_score, task)\n",
        "    \n",
        "        print('%s  acc: %.3f  auc:%.3f' % (split, acc, auc))\n",
        "\n",
        "        \n",
        "print('==> Evaluating ...')\n",
        "test('train')\n",
        "test('test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52SsL7YNcUh5"
      },
      "source": [
        "Design a CNN with **three Conv layers** and **three FC layers**. Train the model on the training set, use the validation set to choose the best design among at least three different choices, and test the chosen model on the test set. Report the four metrics M1 to M4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oTJLdHWcViM"
      },
      "source": [
        "# define a simple CNN model\n",
        "\n",
        "class CNN_A(nn.Module):\n",
        "    \"\"\"\n",
        "    3 Convolutional layers and 3 FC layers\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(CNN_A, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, kernel_size=3),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(16, 64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "        \n",
        "        # self.layer4 = nn.Sequential(\n",
        "        #     nn.Conv2d(64, 64, kernel_size=3),\n",
        "        #     nn.BatchNorm2d(64),\n",
        "        #     nn.ReLU())\n",
        "\n",
        "        # self.layer5 = nn.Sequential(\n",
        "        #     nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "        #     nn.BatchNorm2d(64),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64 * 4 * 4, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fc3 = nn.Sequential(\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = CNN_A(in_channels=n_channels, num_classes=n_classes)\n",
        "print(model)\n",
        "    \n",
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmUSm8fMcboF"
      },
      "source": [
        "wandblogger = WandbLogger()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    \n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        # forward + backward + optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = criterion(outputs, targets)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7UqLPdNciMq"
      },
      "source": [
        "# evaluation\n",
        "\n",
        "def test(split):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([])\n",
        "    y_score = torch.tensor([])\n",
        "    \n",
        "    data_loader = train_loader if split == 'train' else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                m = nn.Sigmoid()\n",
        "                outputs = m(outputs)\n",
        "            else:\n",
        "                targets = targets.squeeze().long()\n",
        "                m = nn.Softmax(dim=1)\n",
        "                outputs = m(outputs)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "        y_true = y_true.numpy()\n",
        "        y_score = y_score.detach().numpy()\n",
        "        auc = getAUC(y_true, y_score, task)\n",
        "        acc = getACC(y_true, y_score, task)\n",
        "    \n",
        "        print('%s  acc: %.3f  auc:%.3f' % (split, acc, auc))\n",
        "\n",
        "        \n",
        "print('==> Evaluating ...')\n",
        "test('train')\n",
        "test('test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t6w2okK_Pwl"
      },
      "source": [
        "## D. Unsupervised learning on Fashion-MNIST\n",
        "\n",
        "- Apply PCA to all images of these two chosen classes. Visualise the top 5 eigenvectors as images and display them in the order of descending corresponding values (the one corresponding to the largest eigenvalue first). [1 marks]\n",
        "- Use the top 30 PCs to reconstruct 10 images, with 5 from each class (any 5 images are fine from each class). Show these 10 pairs of reconstructed and original images. [1 marks]\n",
        "\n",
        "- Visualise the two-dimensional PCA representations of all data points in a 2D plane (i.e. using the top two PCs). Use different colours/markers for the two classes for better visualisation (Hint: You need to use the class labels here for visualisation). [1 marks]\n",
        "- Use spectral clustering to cluster all data points as represented by the top two PCs (clustering of two-dimensional vectors, where each vector has two values, PC1 and PC2). Visualise the two clusters with different colours/markers in 2D. [2 marks].\n",
        "- Design a new autoencoder with five Conv2d layers and five ConvTranspose2d layers. You are free to choose the activation functions and settings such as stride and padding. Train this new autoencoder on all images of these two chosen classes for at least 20 epochs. Plot the loss against the epoch. [2 marks]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn-AMWMVNsaY"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVFgLN1n9ubQ"
      },
      "source": [
        "def get_fashion_mnist_test_loaders(batch_size=128):\n",
        "    \"\"\"Fashion MNIST dataloader with (32, 32) sized images.\"\"\"\n",
        "    # Resize images so they are a power of 2\n",
        "    all_transforms = transforms.Compose([\n",
        "        transforms.Resize(32),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    # Get test data\n",
        "    test_data = datasets.FashionMNIST('../fashion_data', train=False,\n",
        "                                      transform=all_transforms, download=True)\n",
        "    # Create dataloaders\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "    return test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6-CYDCG-q-G"
      },
      "source": [
        "get_fashion_mnist_test_loaders()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67cnTUnoeR9i"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "X = np.array(mnist_data[:][0][0].numpy()).reshape(1, 28*28)\n",
        "for i in range(1, len(mnist_data[:])):\n",
        "    X = np.append(X,np.array(mnist_data[:][i][0].numpy()).reshape(1, 28*28),axis = 0)\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=0.95)\n",
        "pca.fit(X)\n",
        "cov_matrix = np.dot(X.T, X) / len(X)\n",
        "\n",
        "for eigenvector in pca.components_[:30]:\n",
        "    print(np.dot(eigenvector.T, np.dot(cov_matrix, eigenvector)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE91N9ZPZHwT"
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    \"\"\"\n",
        "    An Autoencoder with 5 Conv2d layers and 5 ConvTranspose2d layers\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            # 1 input image channel, 16 output channel, 3x3 square convolution\n",
        "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, 3, stride=2, padding=1),\n",
        "            nn.ReLu(),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 7)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 7),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()  #to range [0, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9EeAyS1csHs"
      },
      "source": [
        "myAE=Autoencoder()\n",
        "print(myAE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoeymC6vcuKC"
      },
      "source": [
        "params = list(myAE.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())  # First Conv2d's .weight\n",
        "print(params[1].size())  # First Conv2d's .bias\n",
        "print(params[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3NoeIYgcxKD"
      },
      "source": [
        "#Training (optimisation) parameters\n",
        "batch_size=64\n",
        "learning_rate=1e-3\n",
        "max_epochs = 20\n",
        "\n",
        "#Choose mean square error loss\n",
        "criterion = nn.MSELoss() \n",
        "#Choose the Adam optimiser\n",
        "optimizer = torch.optim.Adam(myAE.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "#Specify how the data will be loaded in batches (with random shuffling)\n",
        "train_loader = torch.utils.data.DataLoader(mnist_data, batch_size=batch_size, shuffle=True)\n",
        "#Storage\n",
        "outputs = []\n",
        "\n",
        "#Start training\n",
        "for epoch in range(max_epochs):\n",
        "    for data in train_loader:\n",
        "        img, label = data\n",
        "        optimizer.zero_grad()\n",
        "        recon = myAE(img)\n",
        "        loss = criterion(recon, img)\n",
        "        loss.backward()\n",
        "        optimizer.step()            \n",
        "    if (epoch % 2) == 0:\n",
        "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
        "    outputs.append((epoch, img, recon),)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_adxk00etTWp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}